{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data process\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from typing import Dict, Tuple, Optional, List, Union\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "DEBUG_PRINT = False\n",
    "\n",
    "class PrototypicalData(object):\n",
    "    def __init__(self, output_path: str, sequence_length: int = 100, num_classes: int = 2, num_support: int = 5,\n",
    "                 num_queries: int = 50, num_tasks: int = 1000, num_eval_tasks: int = 100,\n",
    "                 stop_word_path: Optional[str] = None,\n",
    "                 embedding_size: Optional[int] = None, low_freq: int = 5,\n",
    "                 word_vector_path: Optional[str] = None, is_training: bool = True):\n",
    "        \"\"\"\n",
    "        init method\n",
    "        :param output_path: path of train/eval data\n",
    "        :param num_classes: number of support class\n",
    "        :param num_support: number of support sample per class\n",
    "        :param num_queries: number of query sample per class\n",
    "        :param num_tasks: number of pre-sampling tasks, this will speeding up train\n",
    "        :param num_eval_tasks: number of pre-sampling tasks in eval stage\n",
    "        :param stop_word_path: path of stop word file\n",
    "        :param embedding_size: embedding size\n",
    "        :param low_freq: frequency of words\n",
    "        :param word_vector_path: path of word vector file(eg. word2vec, glove)\n",
    "        :param is_training: bool\n",
    "        \"\"\"\n",
    "\n",
    "        self.__output_path = output_path\n",
    "        if not os.path.exists(self.__output_path):\n",
    "            os.makedirs(self.__output_path)\n",
    "\n",
    "        self.__sequence_length = sequence_length\n",
    "        self.__num_classes = num_classes\n",
    "        self.__num_support = num_support\n",
    "        self.__num_queries = num_queries\n",
    "        self.__num_tasks = num_tasks\n",
    "        self.__num_eval_tasks = num_eval_tasks\n",
    "        self.__stop_word_path = stop_word_path\n",
    "        self.__embedding_size = embedding_size\n",
    "        self.__low_freq = low_freq\n",
    "        self.__word_vector_path = word_vector_path\n",
    "        self.__is_training = is_training\n",
    "\n",
    "        self.vocab_size = None\n",
    "        self.word_vectors = None\n",
    "        self.current_category_index = 0  # record current sample category\n",
    "\n",
    "        print(\"stop word path: \", self.__stop_word_path)\n",
    "        print(\"word vector path: \", self.__word_vector_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(data_path: str) -> Dict[str, Dict[str, List[List[str]]]]:\n",
    "        \"\"\"\n",
    "        read train/eval data\n",
    "        :param data_path:\n",
    "        :return: dict. {class_name: {sentiment: [[]], }, ...}\n",
    "        \"\"\"\n",
    "        category_files = os.listdir(data_path)\n",
    "        categories_data = {}\n",
    "        for category_file in category_files:\n",
    "            file_path = os.path.join(data_path, category_file)\n",
    "            sentiment_data = {}\n",
    "            with open(file_path, \"r\", encoding=\"utf8\") as fr:\n",
    "                for line in fr.readlines():\n",
    "                    content, label = line.strip().split(\"\\t\")\n",
    "                    if sentiment_data.get(label, None):\n",
    "                        sentiment_data[label].append(content.split(\" \"))\n",
    "                    else:\n",
    "                        sentiment_data[label] = [content.split(\" \")]\n",
    "\n",
    "            # print(\"task name: \", category_file)\n",
    "            # print(\"pos samples length: \", len(sentiment_data[\"1\"]))\n",
    "            # print(\"neg samples length: \", len(sentiment_data[\"-1\"]))\n",
    "            categories_data[category_file] = sentiment_data\n",
    "        return categories_data\n",
    "\n",
    "    def remove_stop_word(self, data: Dict[str, Dict[str, List[List[str]]]]) -> List[str]:\n",
    "        \"\"\"\n",
    "        remove low frequency words and stop words, construct vocab\n",
    "        :param data: {class_name: {sentiment: [[]], }, ...}\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        all_words = []\n",
    "        for category, category_data in data.items():\n",
    "            for sentiment, sentiment_data in category_data.items():\n",
    "                all_words.extend(list(chain(*sentiment_data)))\n",
    "        word_count = Counter(all_words)  # statistic the frequency of words\n",
    "        sort_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # remove low frequency word\n",
    "        words = [item[0] for item in sort_word_count if item[1] > self.__low_freq]\n",
    "\n",
    "        # if stop word file exists, then remove stop words\n",
    "        if self.__stop_word_path:\n",
    "            with open(self.__stop_word_path, \"r\", encoding=\"utf8\") as fr:\n",
    "                stop_words = [line.strip() for line in fr.readlines()]\n",
    "            words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        return words\n",
    "\n",
    "    def get_word_vectors(self, vocab: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        load word vector file,\n",
    "        :param vocab: vocab\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pad_vector = np.zeros(self.__embedding_size)  # set the \"<pad>\" vector to 0\n",
    "        word_vectors = (1 / np.sqrt(len(vocab) - 1) * (2 * np.random.rand(len(vocab) - 1, self.__embedding_size) - 1))\n",
    "        word_vectors = np.vstack((pad_vector, word_vectors))\n",
    "        if DEBUG_PRINT:\n",
    "            # print(vocab)\n",
    "            print(f\"get_word_vectors word_vectors={word_vectors.shape}\")\n",
    "        \n",
    "        # load glove vectors\n",
    "        # glove_vector = {}\n",
    "        # with open(self.__word_vector_path, \"r\", encoding=\"utf8\") as fr:\n",
    "        #     for line in fr.readlines():\n",
    "        #         line_list = line.strip().split(\" \")\n",
    "        #         glove_vector[line_list[0]] = line_list[1:]\n",
    "\n",
    "        # for i in range(1, len(vocab)):\n",
    "        #     if glove_vector.get(vocab[i], None):\n",
    "        #         word_vectors[i, :] = glove_vector[vocab[i]]\n",
    "        #     else:\n",
    "        #         print(vocab[i] + \"not exist word vector file\")\n",
    "\n",
    "        # # load gensim word2vec vectors\n",
    "        # if os.path.splitext(self.__word_vector_path)[-1] == \".bin\":\n",
    "        #     word_vec = gensim.models.KeyedVectors.load_word2vec_format(self.__word_vector_path, binary=True)\n",
    "        # else:\n",
    "        #     word_vec = gensim.models.KeyedVectors.load_word2vec_format(self.__word_vector_path)\n",
    "        #\n",
    "        # for i in range(1, len(vocab)):\n",
    "        #     try:\n",
    "        #         vector = word_vec.wv[vocab[i]]\n",
    "        #         word_vectors[i, :] = vector\n",
    "        #     except:\n",
    "        #         print(vocab[i] + \"not exist word vector file\")\n",
    "\n",
    "        return word_vectors\n",
    "\n",
    "    def gen_vocab(self, words: List[str]) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        generate word_to_index mapping table\n",
    "        :param words:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.__is_training:\n",
    "            vocab = [\"<pad>\", \"<unk>\"] + words\n",
    "\n",
    "            self.vocab_size = len(vocab)\n",
    "\n",
    "            if self.__word_vector_path:\n",
    "                word_vectors = self.get_word_vectors(vocab)\n",
    "                self.word_vectors = word_vectors\n",
    "                # save word vector to npy file\n",
    "                np.save(os.path.join(self.__output_path, \"word_vectors.npy\"), self.word_vectors)\n",
    "\n",
    "            word_to_index = dict(zip(vocab, list(range(len(vocab)))))\n",
    "\n",
    "            # save word_to_index to json file\n",
    "            with open(os.path.join(self.__output_path, \"word_to_index.json\"), \"w\") as f:\n",
    "                json.dump(word_to_index, f)\n",
    "        else:\n",
    "            with open(os.path.join(self.__output_path, \"word_to_index.json\"), \"r\") as f:\n",
    "                word_to_index = json.load(f)\n",
    "\n",
    "        return word_to_index\n",
    "\n",
    "    @staticmethod\n",
    "    def trans_to_index(data: Dict[str, Dict[str, List[List[str]]]], word_to_index: Dict[str, int]) -> \\\n",
    "            Dict[str, Dict[str, List[List[int]]]]:\n",
    "        \"\"\"\n",
    "        transformer token to id\n",
    "        :param data:\n",
    "        :param word_to_index:\n",
    "        :return: {class_name: [[], [], ], ..}\n",
    "        \"\"\"\n",
    "        data_ids = {category: {sentiment: [[word_to_index.get(token, word_to_index[\"<unk>\"]) for token in line]\n",
    "                                           for line in sentiment_data]\n",
    "                               for sentiment, sentiment_data in category_data.items()}\n",
    "                    for category, category_data in data.items()}\n",
    "        return data_ids\n",
    "\n",
    "    def choice_support_query(self, task_data: Dict[str, List[List[int]]])\\\n",
    "            -> Tuple[List[List[List[int]]], List[List[int]], List[int]]:\n",
    "        \"\"\"\n",
    "        randomly selecting support set, query set form a task.\n",
    "        :param task_data: all data for a task\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        label_to_index = {\"1\": 0, \"-1\": 1}\n",
    "        # if self.__is_training:\n",
    "        #     with open(os.path.join(self.__output_path, \"label_to_index.json\"), \"w\") as f:\n",
    "        #         json.dump(label_to_index, f)\n",
    "\n",
    "        pos_samples = task_data[\"1\"]\n",
    "        neg_samples = task_data[\"-1\"]\n",
    "        pos_support = random.sample(pos_samples, self.__num_support)\n",
    "        neg_support = random.sample(neg_samples, self.__num_support)\n",
    "\n",
    "        pos_others = copy.copy(pos_samples)\n",
    "        [pos_others.remove(data) for data in pos_support]\n",
    "\n",
    "        neg_others = copy.copy(neg_samples)\n",
    "        [neg_others.remove(data) for data in neg_support]\n",
    "\n",
    "        pos_query = random.sample(pos_others, self.__num_queries)\n",
    "        neg_query = random.sample(neg_others, self.__num_queries)\n",
    "\n",
    "        # padding\n",
    "        pos_support = self.padding(pos_support)\n",
    "        neg_support = self.padding(neg_support)\n",
    "        pos_query = self.padding(pos_query)\n",
    "        neg_query = self.padding(neg_query)\n",
    "\n",
    "        support_set = [pos_support, neg_support]  # [num_classes, num_support, sequence_length]\n",
    "        query_set = pos_query + neg_query  # [num_classes * num_queries, sequence_length]\n",
    "        labels = [label_to_index[\"1\"]] * len(pos_query) + [label_to_index[\"-1\"]] * len(neg_query)\n",
    "\n",
    "        return support_set, query_set, labels\n",
    "\n",
    "    def samples(self, data_ids: Dict[str, Dict[str, List[List[int]]]]) \\\n",
    "            -> List[Dict[str, Union[List[List[List[int]]], List[List[int]], List[int]]]]:\n",
    "        \"\"\"\n",
    "        positive and negative sample from raw data\n",
    "        :param data_ids:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # product name list\n",
    "        category_list = list(data_ids.keys())\n",
    "\n",
    "        tasks = []\n",
    "        if self.__is_training:\n",
    "            num_tasks = self.__num_tasks\n",
    "        else:\n",
    "            num_tasks = self.__num_eval_tasks\n",
    "        for i in range(num_tasks):\n",
    "            # randomly choice a category to construct train sample\n",
    "            try:\n",
    "                support_category = random.choice(category_list)\n",
    "                support_set, query_set, labels = self.choice_support_query(data_ids[support_category])\n",
    "                tasks.append(dict(support=support_set, queries=query_set, labels=labels))\n",
    "            except:\n",
    "                pass\n",
    "        return tasks\n",
    "\n",
    "    def gen_data(self, file_path: str) -> Dict[str, Dict[str, List[List[int]]]]:\n",
    "        \"\"\"\n",
    "        Generate data that is eventually input to the model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # load data\n",
    "        data = self.load_data(file_path)\n",
    "        # remove stop word\n",
    "        words = self.remove_stop_word(data)\n",
    "        word_to_index = self.gen_vocab(words)\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "\n",
    "        data_ids = self.trans_to_index(data, word_to_index)\n",
    "        return data_ids, data\n",
    "\n",
    "    def padding(self, sentences: List[List[int]]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        padding according to the predefined sequence length\n",
    "        :param sentences:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        sentence_pad = [sentence[:self.__sequence_length] if len(sentence) > self.__sequence_length\n",
    "                        else sentence + [0] * (self.__sequence_length - len(sentence))\n",
    "                        for sentence in sentences]\n",
    "        return sentence_pad\n",
    "\n",
    "    def next_batch(self, data_ids: Dict[str, Dict[str, List[List[int]]]]) \\\n",
    "            -> Dict[str, Union[List[List[List[int]]], List[List[int]], List[int]]]:\n",
    "        \"\"\"\n",
    "        train a task at every turn\n",
    "        :param data_ids:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        tasks = self.samples(data_ids)\n",
    "\n",
    "        for task in tasks:\n",
    "            yield task\n",
    "\n",
    "config = {\n",
    "  \"model_name\": \"prototypical\",\n",
    "  \"epochs\": 30,\n",
    "  \"checkpoint_every\": 100,\n",
    "  \"eval_every\": 500,\n",
    "  \"learning_rate\": 1e-3,\n",
    "  \"optimization\": \"adam\",\n",
    "  \"embedding_size\": 300,\n",
    "  \"hidden_sizes\": [128],\n",
    "  \"attention_size\": 64,\n",
    "  \"num_support\": 10,\n",
    "  \"num_queries\": 50,\n",
    "  \"num_classes\": 2,\n",
    "  \"num_tasks\": 200,\n",
    "  \"num_eval_tasks\": 100,\n",
    "  \"low_freq\": 3,\n",
    "  \"sequence_length\": 200,\n",
    "  \"keep_prob\": 0.7,\n",
    "  \"l2_reg_lambda\": 0.0,\n",
    "  \"max_grad_norm\": 5.0,\n",
    "  \"train_data\": \"./reviews/newtrain\",\n",
    "  \"eval_data\": \"./reviews/neweval\",\n",
    "  \"stop_word_path\": \"./reviews/english\",\n",
    "  \"output_path\": \"./output/prototypical\",\n",
    "  \"word_vector_path\": \"./word_embedded/new_word2vec_model.txt\",\n",
    "  \"ckpt_model_path\": \"./output/prototypical/ckpt_model\",\n",
    "  \"pb_model_path\": \"./output/prototypical/pb_model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "performance metrics function\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def accuracy(pred_y: torch.Tensor, true_y: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.sum(pred_y == true_y) / len(pred_y)\n",
    "\n",
    "\n",
    "def binary_precision(pred_y: torch.Tensor, true_y: torch.Tensor, positive=1):\n",
    "    \"\"\"\n",
    "    Calculate the precision of binary classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param positive: index of positive label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tp = np.sum((pred_y == positive) & (true_y == positive))\n",
    "    fp = np.sum((pred_y == positive) & (true_y != positive))\n",
    "    # fn = np.sum((pred_y != positive) & (true_y == positive))\n",
    "    # tn = np.sum((pred_y != positive) & (true_y != positive))\n",
    "    if (tp + fp) != 0:\n",
    "        return tp / (tp + fp)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def binary_recall(pred_y, true_y, positive=1):\n",
    "    \"\"\"\n",
    "    Calculate the recall of binary classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param positive: index of positive label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tp = np.sum((pred_y == positive) & (true_y == positive))\n",
    "    # fp = np.sum((pred_y == positive) & (true_y != positive))\n",
    "    fn = np.sum((pred_y != positive) & (true_y == positive))\n",
    "    # tn = np.sum((pred_y != positive) & (true_y != positive))\n",
    "    if (tp + fn) != 0:\n",
    "        return tp / (tp + fn)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def binary_f_beta(pred_y, true_y, beta=1.0, positive=1):\n",
    "    \"\"\"\n",
    "    Calculate the f beta of binary classification\n",
    "    :param pred_y: predict result\n",
    "    :param beta: beta parameter\n",
    "    :param true_y: true result\n",
    "    :param positive: index of positive label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    precision = binary_precision(pred_y, true_y, positive)\n",
    "    recall = binary_recall(pred_y, true_y, positive)\n",
    "    if (beta * beta * precision + recall) != 0:\n",
    "        return (1 + beta * beta) * precision * recall / (beta * beta * precision + recall)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_binary_metrics(pred_y, true_y, f_beta=1.0):\n",
    "    \"\"\"\n",
    "    Calculate various performance metrics of binary classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param f_beta: beta parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    acc = accuracy(pred_y, true_y)\n",
    "    recall = binary_recall(pred_y, true_y)\n",
    "    precision = binary_precision(pred_y, true_y)\n",
    "    f_beta = binary_f_beta(pred_y, true_y, f_beta)\n",
    "    return acc, recall, precision, f_beta\n",
    "\n",
    "\n",
    "def multi_precision(pred_y, true_y, labels):\n",
    "    \"\"\"\n",
    "    Calculate the precision of multi classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param labels: label list\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    precisions = [binary_precision(pred_y, true_y, label) for label in labels]\n",
    "    prec = np.mean(precisions)\n",
    "    return prec\n",
    "\n",
    "\n",
    "def multi_recall(pred_y, true_y, labels):\n",
    "    \"\"\"\n",
    "    Calculate the recall of multi classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param labels: label list\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    recalls = [binary_recall(pred_y, true_y, label) for label in labels]\n",
    "    rec = np.mean(recalls)\n",
    "    return rec\n",
    "\n",
    "\n",
    "def multi_f_beta(pred_y, true_y, labels, beta=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the f value of multi classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param labels: label list\n",
    "    :param beta: beta parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f_betas = [binary_f_beta(pred_y, true_y, beta, label) for label in labels]\n",
    "    f_beta = np.mean(f_betas)\n",
    "    return f_beta\n",
    "\n",
    "\n",
    "def get_multi_metrics(pred_y, true_y, labels, f_beta=1.0):\n",
    "    \"\"\"\n",
    "    Calculate various performance metrics of multi classification\n",
    "    :param pred_y: predict result\n",
    "    :param true_y: true result\n",
    "    :param labels: label list\n",
    "    :param beta: beta parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    acc = accuracy(pred_y, true_y)\n",
    "    recall = multi_recall(pred_y, true_y, labels)\n",
    "    precision = multi_precision(pred_y, true_y, labels)\n",
    "    f_beta = multi_f_beta(pred_y, true_y, labels, f_beta)\n",
    "    return acc, recall, precision, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word path:  ./reviews/english\n",
      "word vector path:  ./word_embedded/new_word2vec_model.txt\n",
      "stop word path:  ./reviews/english\n",
      "word vector path:  ./word_embedded/new_word2vec_model.txt\n",
      "VAL: epoch=1 loss=0.658 accuracy=0.534 recalls=0.534 precs=0.611 fbeta=0.426\n",
      "VAL: epoch=1 loss=0.622 accuracy=0.580 recalls=0.580 precs=0.652 fbeta=0.514\n",
      "TRAIN: epoch=1 loss=0.5843609571456909 avg_loss=0.6603516525030136\n",
      "VAL: epoch=2 loss=0.570 accuracy=0.580 recalls=0.580 precs=0.720 fbeta=0.492\n",
      "VAL: epoch=2 loss=0.534 accuracy=0.704 recalls=0.704 precs=0.746 fbeta=0.689\n",
      "TRAIN: epoch=2 loss=0.6051499247550964 avg_loss=0.6185775139927864\n",
      "VAL: epoch=3 loss=0.501 accuracy=0.741 recalls=0.741 precs=0.744 fbeta=0.740\n",
      "VAL: epoch=3 loss=0.480 accuracy=0.749 recalls=0.749 precs=0.776 fbeta=0.741\n",
      "TRAIN: epoch=3 loss=0.41845524311065674 avg_loss=0.5750580715139707\n",
      "VAL: epoch=4 loss=0.465 accuracy=0.768 recalls=0.768 precs=0.772 fbeta=0.768\n",
      "VAL: epoch=4 loss=0.444 accuracy=0.761 recalls=0.761 precs=0.772 fbeta=0.758\n",
      "TRAIN: epoch=4 loss=0.3437148332595825 avg_loss=0.5391409050300717\n",
      "VAL: epoch=5 loss=0.430 accuracy=0.766 recalls=0.766 precs=0.772 fbeta=0.765\n",
      "VAL: epoch=5 loss=0.424 accuracy=0.770 recalls=0.770 precs=0.780 fbeta=0.768\n",
      "TRAIN: epoch=5 loss=0.4776483476161957 avg_loss=0.5092813545763493\n",
      "VAL: epoch=6 loss=0.426 accuracy=0.637 recalls=0.637 precs=0.771 fbeta=0.577\n",
      "VAL: epoch=6 loss=0.420 accuracy=0.738 recalls=0.738 precs=0.796 fbeta=0.722\n",
      "TRAIN: epoch=6 loss=0.24544857442378998 avg_loss=0.4830754466727376\n",
      "VAL: epoch=7 loss=0.404 accuracy=0.770 recalls=0.770 precs=0.784 fbeta=0.767\n",
      "VAL: epoch=7 loss=0.398 accuracy=0.738 recalls=0.738 precs=0.787 fbeta=0.725\n",
      "TRAIN: epoch=7 loss=0.32850638031959534 avg_loss=0.46144428166959967\n",
      "VAL: epoch=8 loss=0.385 accuracy=0.713 recalls=0.713 precs=0.799 fbeta=0.687\n",
      "VAL: epoch=8 loss=0.401 accuracy=0.728 recalls=0.728 precs=0.792 fbeta=0.710\n",
      "TRAIN: epoch=8 loss=0.25733330845832825 avg_loss=0.4416770803183317\n",
      "VAL: epoch=9 loss=0.402 accuracy=0.691 recalls=0.691 precs=0.773 fbeta=0.665\n",
      "VAL: epoch=9 loss=0.396 accuracy=0.670 recalls=0.670 precs=0.779 fbeta=0.632\n",
      "TRAIN: epoch=9 loss=0.25301405787467957 avg_loss=0.4233348454617792\n",
      "VAL: epoch=10 loss=0.378 accuracy=0.712 recalls=0.712 precs=0.800 fbeta=0.687\n",
      "VAL: epoch=10 loss=0.398 accuracy=0.681 recalls=0.681 precs=0.783 fbeta=0.646\n",
      "TRAIN: epoch=10 loss=0.4319078028202057 avg_loss=0.4072758906707168\n",
      "VAL: epoch=11 loss=0.384 accuracy=0.770 recalls=0.770 precs=0.807 fbeta=0.762\n",
      "VAL: epoch=11 loss=0.364 accuracy=0.698 recalls=0.698 precs=0.785 fbeta=0.671\n",
      "TRAIN: epoch=11 loss=0.3230782449245453 avg_loss=0.3918617252937772\n",
      "VAL: epoch=12 loss=0.395 accuracy=0.708 recalls=0.708 precs=0.795 fbeta=0.683\n",
      "VAL: epoch=12 loss=0.382 accuracy=0.652 recalls=0.652 precs=0.780 fbeta=0.602\n",
      "TRAIN: epoch=12 loss=0.24761322140693665 avg_loss=0.3778104738673816\n",
      "VAL: epoch=13 loss=0.376 accuracy=0.656 recalls=0.656 precs=0.785 fbeta=0.608\n",
      "VAL: epoch=13 loss=0.385 accuracy=0.677 recalls=0.677 precs=0.791 fbeta=0.638\n",
      "TRAIN: epoch=13 loss=0.2199816107749939 avg_loss=0.36492903861575404\n",
      "VAL: epoch=14 loss=0.375 accuracy=0.701 recalls=0.701 precs=0.797 fbeta=0.672\n",
      "VAL: epoch=14 loss=0.386 accuracy=0.651 recalls=0.651 precs=0.787 fbeta=0.599\n",
      "TRAIN: epoch=14 loss=0.09708236902952194 avg_loss=0.3524423142549183\n",
      "VAL: epoch=15 loss=0.382 accuracy=0.738 recalls=0.738 precs=0.799 fbeta=0.724\n",
      "VAL: epoch=15 loss=0.366 accuracy=0.757 recalls=0.757 precs=0.815 fbeta=0.743\n",
      "TRAIN: epoch=15 loss=0.12604528665542603 avg_loss=0.34134850635379554\n",
      "VAL: epoch=16 loss=0.359 accuracy=0.725 recalls=0.725 precs=0.804 fbeta=0.704\n",
      "VAL: epoch=16 loss=0.377 accuracy=0.693 recalls=0.693 precs=0.795 fbeta=0.660\n",
      "TRAIN: epoch=16 loss=0.1440349519252777 avg_loss=0.3307485653134063\n",
      "VAL: epoch=17 loss=0.373 accuracy=0.734 recalls=0.734 precs=0.812 fbeta=0.713\n",
      "VAL: epoch=17 loss=0.374 accuracy=0.762 recalls=0.762 precs=0.815 fbeta=0.750\n",
      "TRAIN: epoch=17 loss=0.09128356724977493 avg_loss=0.3209448489963132\n",
      "VAL: epoch=18 loss=0.391 accuracy=0.679 recalls=0.679 precs=0.791 fbeta=0.642\n",
      "VAL: epoch=18 loss=0.374 accuracy=0.764 recalls=0.764 precs=0.814 fbeta=0.753\n",
      "TRAIN: epoch=18 loss=0.10714008659124374 avg_loss=0.3113017212640908\n",
      "VAL: epoch=19 loss=0.409 accuracy=0.775 recalls=0.775 precs=0.793 fbeta=0.771\n",
      "VAL: epoch=19 loss=0.377 accuracy=0.644 recalls=0.644 precs=0.783 fbeta=0.590\n",
      "TRAIN: epoch=19 loss=0.08549681305885315 avg_loss=0.3023253912488489\n",
      "VAL: epoch=20 loss=0.387 accuracy=0.683 recalls=0.683 precs=0.794 fbeta=0.646\n",
      "VAL: epoch=20 loss=0.380 accuracy=0.736 recalls=0.736 precs=0.805 fbeta=0.718\n",
      "TRAIN: epoch=20 loss=0.21744897961616516 avg_loss=0.2940624802717939\n",
      "VAL: epoch=21 loss=0.402 accuracy=0.726 recalls=0.726 precs=0.800 fbeta=0.706\n",
      "VAL: epoch=21 loss=0.373 accuracy=0.710 recalls=0.710 precs=0.800 fbeta=0.683\n",
      "TRAIN: epoch=21 loss=0.10347288846969604 avg_loss=0.28604253676409525\n",
      "VAL: epoch=22 loss=0.395 accuracy=0.720 recalls=0.720 precs=0.802 fbeta=0.697\n",
      "VAL: epoch=22 loss=0.392 accuracy=0.692 recalls=0.692 precs=0.794 fbeta=0.659\n",
      "TRAIN: epoch=22 loss=0.10532761365175247 avg_loss=0.2782936904490502\n",
      "VAL: epoch=23 loss=0.380 accuracy=0.739 recalls=0.739 precs=0.806 fbeta=0.722\n",
      "VAL: epoch=23 loss=0.370 accuracy=0.744 recalls=0.744 precs=0.806 fbeta=0.729\n",
      "TRAIN: epoch=23 loss=0.21426840126514435 avg_loss=0.2709727848009409\n",
      "VAL: epoch=24 loss=0.379 accuracy=0.726 recalls=0.726 precs=0.801 fbeta=0.707\n",
      "VAL: epoch=24 loss=0.364 accuracy=0.756 recalls=0.756 precs=0.812 fbeta=0.744\n",
      "TRAIN: epoch=24 loss=0.08719649165868759 avg_loss=0.2640194627502933\n",
      "VAL: epoch=25 loss=0.385 accuracy=0.791 recalls=0.791 precs=0.810 fbeta=0.787\n",
      "VAL: epoch=25 loss=0.369 accuracy=0.727 recalls=0.727 precs=0.794 fbeta=0.708\n",
      "TRAIN: epoch=25 loss=0.09013564139604568 avg_loss=0.2571943190667778\n",
      "VAL: epoch=26 loss=0.409 accuracy=0.745 recalls=0.745 precs=0.795 fbeta=0.733\n",
      "VAL: epoch=26 loss=0.409 accuracy=0.683 recalls=0.683 precs=0.795 fbeta=0.646\n",
      "TRAIN: epoch=26 loss=0.022950001060962677 avg_loss=0.25076729048992724\n",
      "VAL: epoch=27 loss=0.409 accuracy=0.712 recalls=0.712 precs=0.796 fbeta=0.688\n",
      "VAL: epoch=27 loss=0.392 accuracy=0.720 recalls=0.720 precs=0.800 fbeta=0.697\n",
      "TRAIN: epoch=27 loss=0.04203181713819504 avg_loss=0.2447122645376388\n",
      "VAL: epoch=28 loss=0.382 accuracy=0.714 recalls=0.714 precs=0.799 fbeta=0.690\n",
      "VAL: epoch=28 loss=0.389 accuracy=0.760 recalls=0.760 precs=0.808 fbeta=0.749\n",
      "TRAIN: epoch=28 loss=0.04280909523367882 avg_loss=0.23886856971375112\n",
      "VAL: epoch=29 loss=0.399 accuracy=0.792 recalls=0.792 precs=0.798 fbeta=0.791\n",
      "VAL: epoch=29 loss=0.389 accuracy=0.796 recalls=0.796 precs=0.818 fbeta=0.792\n",
      "TRAIN: epoch=29 loss=0.056634582579135895 avg_loss=0.23341588998020724\n",
      "VAL: epoch=30 loss=0.419 accuracy=0.796 recalls=0.796 precs=0.799 fbeta=0.796\n",
      "VAL: epoch=30 loss=0.362 accuracy=0.795 recalls=0.795 precs=0.806 fbeta=0.793\n",
      "TRAIN: epoch=30 loss=0.06531788408756256 avg_loss=0.2280326276696287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def extract_batch(batch: dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    supports = torch.tensor(batch['support'], device=device)\n",
    "    query = torch.tensor(batch['queries'], device=device)\n",
    "    labels = torch.tensor(batch['labels'], device=device)\n",
    "    \n",
    "    # https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "    # https://github.com/sicara/easy-few-shot-learning/blob/master/notebooks/my_first_few_shot_classifier.ipynb\n",
    "\n",
    "    # supports = [num_classes, batch, length]\n",
    "    pos_support = supports[0, :, :]\n",
    "    pos_support_labels = torch.zeros(pos_support.size(0))\n",
    "    neg_support = supports[1, :, :]\n",
    "    neg_support_labels = torch.ones(neg_support.size(0))\n",
    "    supports = torch.cat([pos_support, neg_support], dim=0).to(device=device)\n",
    "    supports_labels = torch.cat([pos_support_labels, neg_support_labels], dim=0).to(device=device)\n",
    "    \n",
    "    return supports, supports_labels, query, labels\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, fs: List[int], channels: int, output_dim: int) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=(n, embedding_dim)) for n in fs\n",
    "        ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(fs) * channels, output_dim)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"CNN x={x.size()}\")\n",
    "        embedded = self.embed(x)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"CNN embeded={embedded.size()}\")\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        output = torch.cat(pooled, dim=1)\n",
    "        return self.fc(output)\n",
    "    \n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self(x).argmax(1)\n",
    "    \n",
    "    def scores(self, batch: dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        supports, supports_labels, query, query_labels = extract_batch(batch)\n",
    "        supports_out = model(supports)\n",
    "        query_out = model(query)\n",
    "\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train support_out={supports_out.size()} query_out={query_out.size()}\")\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train indices={torch.nonzero(supports_labels == 0).size()}\")\n",
    "        proto_pos = supports_out[torch.nonzero(supports_labels == 0)]\n",
    "        proto_neg = supports_out[torch.nonzero(supports_labels == 1)]\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto_pos={proto_pos.size()}\")\n",
    "            \n",
    "        proto_pos = proto_pos.mean(0)\n",
    "        proto_neg = proto_neg.mean(0)\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto_pos_meaned={proto_pos.size()}\")\n",
    "            \n",
    "        proto = torch.cat([proto_pos, proto_neg], dim=0).to(dtype=torch.float)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto={proto.size()}\")\n",
    "            \n",
    "        dists = torch.cdist(query_out, proto)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train dists={dists.size()} labels={query_labels.size()}\")\n",
    "\n",
    "        scores = -dists\n",
    "        return scores, query_out, query_labels\n",
    "    \n",
    "data_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=True)\n",
    "eval_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=False)\n",
    "train_tasks, _ = data_loader.gen_data(config[\"train_data\"])\n",
    "eval_tasks, _ = eval_loader.gen_data(config[\"eval_data\"])\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN(data_loader.vocab_size, 512, [1,2,4], 128, 2).to(device)\n",
    "lr = 0.01\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "total_loss = 0\n",
    "interval = config[\"checkpoint_every\"]\n",
    "current_step = 0\n",
    "\n",
    "ckpt_path = Path(config['ckpt_model_path'])\n",
    "\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    for task in data_loader.next_batch(train_tasks):\n",
    "        model.zero_grad()\n",
    "        # https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "        # https://github.com/sicara/easy-few-shot-learning/blob/master/notebooks/my_first_few_shot_classifier.ipynb\n",
    "    \n",
    "        scores, _, labels = model.scores(task)\n",
    "        \n",
    "        loss = loss_fn(scores, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        current_step += 1\n",
    "        \n",
    "        if current_step % interval == 0:\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                val_accs = []\n",
    "                val_recalls = []\n",
    "                val_precs = []\n",
    "                val_fbeta = []\n",
    "                for task in eval_loader.next_batch(eval_tasks):\n",
    "                    scores, preds_out, labels = model.scores(task)\n",
    "                    preds = preds_out.argmax(1)\n",
    "                    val_loss = loss_fn(scores, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    \n",
    "                    # Move to cpu for faster computation\n",
    "                    acc, recall, prec, f_beta = get_multi_metrics(pred_y=preds.cpu().numpy(),\n",
    "                                                                 true_y=labels.cpu().numpy(),\n",
    "                                                                 labels=np.array([0, 1]))\n",
    "                    val_accs.append(acc)\n",
    "                    val_recalls.append(recall)\n",
    "                    val_precs.append(prec)\n",
    "                    val_fbeta.append(f_beta)\n",
    "                    \n",
    "                print(f\"VAL: epoch={ep} loss={np.mean(val_losses):.03f} accuracy={np.mean(val_accs):.03f} recalls={np.mean(val_recalls):.03f} precs={np.mean(val_precs):.03f} fbeta={np.mean(val_fbeta):.03f}\")\n",
    "        \n",
    "        opt.step()\n",
    "    print(f\"TRAIN: epoch={ep} loss={loss} avg_loss={total_loss/current_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word path:  ./reviews/english\n",
      "word vector path:  ./word_embedded/new_word2vec_model.txt\n",
      "stop word path:  ./reviews/english\n",
      "word vector path:  ./word_embedded/new_word2vec_model.txt\n",
      "VAL: epoch=1 loss=0.655 accuracy=0.556 recalls=0.556 precs=0.565 fbeta=0.538\n",
      "VAL: epoch=1 loss=0.611 accuracy=0.586 recalls=0.586 precs=0.603 fbeta=0.565\n",
      "TRAIN: epoch=1 loss=0.5804505348205566 avg_loss=0.6555341073870659\n",
      "VAL: epoch=2 loss=0.552 accuracy=0.661 recalls=0.661 precs=0.689 fbeta=0.647\n",
      "VAL: epoch=2 loss=0.527 accuracy=0.719 recalls=0.719 precs=0.722 fbeta=0.718\n",
      "TRAIN: epoch=2 loss=0.417949378490448 avg_loss=0.6089077597856521\n",
      "VAL: epoch=3 loss=0.489 accuracy=0.735 recalls=0.735 precs=0.759 fbeta=0.726\n",
      "VAL: epoch=3 loss=0.449 accuracy=0.764 recalls=0.764 precs=0.768 fbeta=0.763\n",
      "TRAIN: epoch=3 loss=0.30760663747787476 avg_loss=0.5650602225959301\n",
      "VAL: epoch=4 loss=0.446 accuracy=0.592 recalls=0.592 precs=0.711 fbeta=0.521\n",
      "VAL: epoch=4 loss=0.432 accuracy=0.746 recalls=0.746 precs=0.766 fbeta=0.740\n",
      "TRAIN: epoch=4 loss=0.48620882630348206 avg_loss=0.5270033440925181\n",
      "VAL: epoch=5 loss=0.403 accuracy=0.692 recalls=0.692 precs=0.755 fbeta=0.668\n",
      "VAL: epoch=5 loss=0.409 accuracy=0.750 recalls=0.750 precs=0.772 fbeta=0.742\n",
      "TRAIN: epoch=5 loss=0.4298488199710846 avg_loss=0.4984863824248314\n",
      "VAL: epoch=6 loss=0.423 accuracy=0.692 recalls=0.692 precs=0.748 fbeta=0.667\n",
      "VAL: epoch=6 loss=0.397 accuracy=0.786 recalls=0.786 precs=0.804 fbeta=0.783\n",
      "TRAIN: epoch=6 loss=0.37410596013069153 avg_loss=0.47196750653286773\n",
      "VAL: epoch=7 loss=0.413 accuracy=0.744 recalls=0.744 precs=0.782 fbeta=0.735\n",
      "VAL: epoch=7 loss=0.373 accuracy=0.791 recalls=0.791 precs=0.798 fbeta=0.789\n",
      "TRAIN: epoch=7 loss=0.38278400897979736 avg_loss=0.4483297420931714\n",
      "VAL: epoch=8 loss=0.392 accuracy=0.717 recalls=0.717 precs=0.750 fbeta=0.704\n",
      "VAL: epoch=8 loss=0.403 accuracy=0.763 recalls=0.763 precs=0.772 fbeta=0.761\n",
      "TRAIN: epoch=8 loss=0.29492661356925964 avg_loss=0.42859416093677283\n",
      "VAL: epoch=9 loss=0.371 accuracy=0.729 recalls=0.729 precs=0.792 fbeta=0.713\n",
      "VAL: epoch=9 loss=0.373 accuracy=0.777 recalls=0.777 precs=0.802 fbeta=0.772\n",
      "TRAIN: epoch=9 loss=0.16531366109848022 avg_loss=0.41002645085255307\n",
      "VAL: epoch=10 loss=0.379 accuracy=0.731 recalls=0.731 precs=0.800 fbeta=0.713\n",
      "VAL: epoch=10 loss=0.371 accuracy=0.618 recalls=0.618 precs=0.777 fbeta=0.549\n",
      "TRAIN: epoch=10 loss=0.27317720651626587 avg_loss=0.39362635546550157\n",
      "VAL: epoch=11 loss=0.357 accuracy=0.775 recalls=0.775 precs=0.809 fbeta=0.769\n",
      "VAL: epoch=11 loss=0.388 accuracy=0.778 recalls=0.778 precs=0.809 fbeta=0.772\n",
      "TRAIN: epoch=11 loss=0.26372629404067993 avg_loss=0.37837803556499155\n",
      "VAL: epoch=12 loss=0.367 accuracy=0.778 recalls=0.778 precs=0.810 fbeta=0.772\n",
      "VAL: epoch=12 loss=0.357 accuracy=0.769 recalls=0.769 precs=0.809 fbeta=0.761\n",
      "TRAIN: epoch=12 loss=0.19103515148162842 avg_loss=0.36437584468784434\n",
      "VAL: epoch=13 loss=0.377 accuracy=0.808 recalls=0.808 precs=0.812 fbeta=0.808\n",
      "VAL: epoch=13 loss=0.356 accuracy=0.730 recalls=0.730 precs=0.808 fbeta=0.710\n",
      "TRAIN: epoch=13 loss=0.1607465147972107 avg_loss=0.35067207322097743\n",
      "VAL: epoch=14 loss=0.397 accuracy=0.693 recalls=0.693 precs=0.798 fbeta=0.660\n",
      "VAL: epoch=14 loss=0.366 accuracy=0.710 recalls=0.710 precs=0.796 fbeta=0.686\n",
      "TRAIN: epoch=14 loss=0.1110396757721901 avg_loss=0.3388092796557716\n",
      "VAL: epoch=15 loss=0.375 accuracy=0.723 recalls=0.723 precs=0.755 fbeta=0.711\n",
      "VAL: epoch=15 loss=0.361 accuracy=0.662 recalls=0.662 precs=0.786 fbeta=0.618\n",
      "TRAIN: epoch=15 loss=0.2395877093076706 avg_loss=0.3275369527799388\n",
      "VAL: epoch=16 loss=0.383 accuracy=0.736 recalls=0.736 precs=0.807 fbeta=0.718\n",
      "VAL: epoch=16 loss=0.362 accuracy=0.810 recalls=0.810 precs=0.818 fbeta=0.809\n",
      "TRAIN: epoch=16 loss=0.15833930671215057 avg_loss=0.31632358849630693\n",
      "VAL: epoch=17 loss=0.380 accuracy=0.790 recalls=0.790 precs=0.804 fbeta=0.788\n",
      "VAL: epoch=17 loss=0.371 accuracy=0.768 recalls=0.768 precs=0.813 fbeta=0.758\n",
      "TRAIN: epoch=17 loss=0.3113176226615906 avg_loss=0.3062725253940067\n",
      "VAL: epoch=18 loss=0.385 accuracy=0.750 recalls=0.750 precs=0.812 fbeta=0.735\n",
      "VAL: epoch=18 loss=0.361 accuracy=0.815 recalls=0.815 precs=0.823 fbeta=0.814\n",
      "TRAIN: epoch=18 loss=0.3029547929763794 avg_loss=0.2971038750735008\n",
      "VAL: epoch=19 loss=0.380 accuracy=0.775 recalls=0.775 precs=0.784 fbeta=0.772\n",
      "VAL: epoch=19 loss=0.368 accuracy=0.675 recalls=0.675 precs=0.730 fbeta=0.650\n",
      "TRAIN: epoch=19 loss=0.16430233418941498 avg_loss=0.2876209417112956\n",
      "VAL: epoch=20 loss=0.369 accuracy=0.793 recalls=0.793 precs=0.815 fbeta=0.789\n",
      "VAL: epoch=20 loss=0.380 accuracy=0.800 recalls=0.800 precs=0.810 fbeta=0.798\n",
      "TRAIN: epoch=20 loss=0.06392396241426468 avg_loss=0.2790616686772555\n",
      "VAL: epoch=21 loss=0.378 accuracy=0.774 recalls=0.774 precs=0.823 fbeta=0.764\n",
      "VAL: epoch=21 loss=0.407 accuracy=0.794 recalls=0.794 precs=0.814 fbeta=0.790\n",
      "TRAIN: epoch=21 loss=0.07908045500516891 avg_loss=0.27067696612416986\n",
      "VAL: epoch=22 loss=0.386 accuracy=0.785 recalls=0.785 precs=0.819 fbeta=0.778\n",
      "VAL: epoch=22 loss=0.368 accuracy=0.810 recalls=0.810 precs=0.819 fbeta=0.809\n",
      "TRAIN: epoch=22 loss=0.11824928969144821 avg_loss=0.2628028454845348\n",
      "VAL: epoch=23 loss=0.353 accuracy=0.820 recalls=0.820 precs=0.823 fbeta=0.819\n",
      "VAL: epoch=23 loss=0.365 accuracy=0.801 recalls=0.801 precs=0.825 fbeta=0.797\n",
      "TRAIN: epoch=23 loss=0.19149711728096008 avg_loss=0.25526810284926676\n",
      "VAL: epoch=24 loss=0.381 accuracy=0.758 recalls=0.758 precs=0.777 fbeta=0.752\n",
      "VAL: epoch=24 loss=0.370 accuracy=0.811 recalls=0.811 precs=0.817 fbeta=0.810\n",
      "TRAIN: epoch=24 loss=0.18351145088672638 avg_loss=0.2480101889098296\n",
      "VAL: epoch=25 loss=0.366 accuracy=0.821 recalls=0.821 precs=0.827 fbeta=0.820\n",
      "VAL: epoch=25 loss=0.385 accuracy=0.790 recalls=0.790 precs=0.800 fbeta=0.788\n",
      "TRAIN: epoch=25 loss=0.06933198869228363 avg_loss=0.2413436655314639\n",
      "VAL: epoch=26 loss=0.397 accuracy=0.784 recalls=0.784 precs=0.813 fbeta=0.778\n",
      "VAL: epoch=26 loss=0.386 accuracy=0.804 recalls=0.804 precs=0.827 fbeta=0.800\n",
      "TRAIN: epoch=26 loss=0.13789959251880646 avg_loss=0.23483134892643787\n",
      "VAL: epoch=27 loss=0.376 accuracy=0.790 recalls=0.790 precs=0.797 fbeta=0.788\n",
      "VAL: epoch=27 loss=0.376 accuracy=0.808 recalls=0.808 precs=0.815 fbeta=0.807\n",
      "TRAIN: epoch=27 loss=0.02867964468896389 avg_loss=0.2289336930393\n",
      "VAL: epoch=28 loss=0.389 accuracy=0.793 recalls=0.793 precs=0.799 fbeta=0.792\n",
      "VAL: epoch=28 loss=0.386 accuracy=0.800 recalls=0.800 precs=0.804 fbeta=0.799\n",
      "TRAIN: epoch=28 loss=0.13104450702667236 avg_loss=0.2231537897450783\n",
      "VAL: epoch=29 loss=0.362 accuracy=0.762 recalls=0.762 precs=0.826 fbeta=0.747\n",
      "VAL: epoch=29 loss=0.360 accuracy=0.825 recalls=0.825 precs=0.841 fbeta=0.822\n",
      "TRAIN: epoch=29 loss=0.0575638972222805 avg_loss=0.21738538774846378\n",
      "VAL: epoch=30 loss=0.385 accuracy=0.814 recalls=0.814 precs=0.826 fbeta=0.812\n",
      "VAL: epoch=30 loss=0.385 accuracy=0.779 recalls=0.779 precs=0.799 fbeta=0.774\n",
      "TRAIN: epoch=30 loss=0.12058163434267044 avg_loss=0.21206244452103662\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def extract_batch(batch: dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    supports = torch.tensor(batch['support'], device=device)\n",
    "    query = torch.tensor(batch['queries'], device=device)\n",
    "    labels = torch.tensor(batch['labels'], device=device)\n",
    "    \n",
    "    # https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "    # https://github.com/sicara/easy-few-shot-learning/blob/master/notebooks/my_first_few_shot_classifier.ipynb\n",
    "\n",
    "    # supports = [num_classes, batch, length]\n",
    "    pos_support = supports[0, :, :]\n",
    "    pos_support_labels = torch.zeros(pos_support.size(0))\n",
    "    neg_support = supports[1, :, :]\n",
    "    neg_support_labels = torch.ones(neg_support.size(0))\n",
    "    supports = torch.cat([pos_support, neg_support], dim=0).to(device=device)\n",
    "    supports_labels = torch.cat([pos_support_labels, neg_support_labels], dim=0).to(device=device)\n",
    "    \n",
    "    return supports, supports_labels, query, labels\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, fs: List[int], channels: int, output_dim: int) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=(n, embedding_dim)) for n in fs\n",
    "        ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(fs) * channels, output_dim)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"CNN x={x.size()}\")\n",
    "        embedded = self.embed(x)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"CNN embeded={embedded.size()}\")\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        output = torch.cat(pooled, dim=1)\n",
    "        return self.fc(output)\n",
    "    \n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self(x).argmax(1)\n",
    "    \n",
    "    def scores(self, batch: dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        supports, supports_labels, query, query_labels = extract_batch(batch)\n",
    "        supports_out = model(supports)\n",
    "        query_out = model(query)\n",
    "\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train support_out={supports_out.size()} query_out={query_out.size()}\")\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train indices={torch.nonzero(supports_labels == 0).size()}\")\n",
    "        proto_pos = supports_out[torch.nonzero(supports_labels == 0)]\n",
    "        proto_neg = supports_out[torch.nonzero(supports_labels == 1)]\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto_pos={proto_pos.size()}\")\n",
    "            \n",
    "        proto_pos = proto_pos.mean(0)\n",
    "        proto_neg = proto_neg.mean(0)\n",
    "        \n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto_pos_meaned={proto_pos.size()}\")\n",
    "            \n",
    "        proto = torch.cat([proto_pos, proto_neg], dim=0).to(dtype=torch.float)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train proto={proto.size()}\")\n",
    "            \n",
    "        dists = torch.cdist(query_out, proto)\n",
    "        if DEBUG_PRINT:\n",
    "            print(f\"train dists={dists.size()} labels={query_labels.size()}\")\n",
    "\n",
    "        scores = -dists\n",
    "        return scores, query_out, query_labels\n",
    "    \n",
    "data_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=True)\n",
    "eval_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=False)\n",
    "train_tasks, _ = data_loader.gen_data(config[\"train_data\"])\n",
    "eval_tasks, _ = eval_loader.gen_data(config[\"eval_data\"])\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN(data_loader.vocab_size, 512, [1,2,4], 256, 2).to(device)\n",
    "model.train()\n",
    "lr = 0.01\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "total_loss = 0\n",
    "interval = config[\"checkpoint_every\"]\n",
    "current_step = 0\n",
    "\n",
    "ckpt_path = Path(config['ckpt_model_path'])\n",
    "\n",
    "ticks = []\n",
    "for ep in range(1, epochs+1):\n",
    "    for task in data_loader.next_batch(train_tasks):\n",
    "        model.zero_grad()\n",
    "        # https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "        # https://github.com/sicara/easy-few-shot-learning/blob/master/notebooks/my_first_few_shot_classifier.ipynb\n",
    "    \n",
    "        scores, _, labels = model.scores(task)\n",
    "        \n",
    "        loss = loss_fn(scores, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        current_step += 1\n",
    "        \n",
    "        if current_step % interval == 0:\n",
    "            with torch.no_grad():\n",
    "                val_losses = []\n",
    "                val_accs = []\n",
    "                val_recalls = []\n",
    "                val_precs = []\n",
    "                val_fbeta = []\n",
    "                for task in eval_loader.next_batch(eval_tasks):\n",
    "                    scores, preds_out, labels = model.scores(task)\n",
    "                    preds = preds_out.argmax(1)\n",
    "                    val_loss = loss_fn(scores, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    \n",
    "                    # Move to cpu for faster computation\n",
    "                    acc, recall, prec, f_beta = get_multi_metrics(pred_y=preds.cpu().numpy(),\n",
    "                                                                 true_y=labels.cpu().numpy(),\n",
    "                                                                 labels=np.array([0, 1]))\n",
    "                    val_accs.append(acc)\n",
    "                    val_recalls.append(recall)\n",
    "                    val_precs.append(prec)\n",
    "                    val_fbeta.append(f_beta)\n",
    "                \n",
    "                mean_loss = np.mean(val_losses)\n",
    "                mean_acc = np.mean(val_accs)\n",
    "                mean_recalss = np.mean(val_recalls)\n",
    "                mean_precs = np.mean(val_precs)\n",
    "                mean_f1b = np.mean(val_fbeta)\n",
    "                print(f\"VAL: epoch={ep} loss={mean_loss:.03f} accuracy={mean_acc:.03f} recalls={mean_recalss:.03f} precs={mean_precs:.03f} fbeta={mean_f1b:.03f}\")\n",
    "\n",
    "                ticks.append(\n",
    "                    ((ep, current_step), mean_loss, mean_acc, mean_recalss, mean_precs, mean_f1b)\n",
    "                )\n",
    "        opt.step()\n",
    "    print(f\"TRAIN: epoch={ep} loss={loss} avg_loss={total_loss/current_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 100), 0.6550026260396485, 0.5560215053763442, 0.5560215053763442, 0.5649300672519706, 0.5383688217515725), ((1, 200), 0.6110553638059266, 0.5858163265306123, 0.5858163265306123, 0.6034250659045903, 0.5651431731659589), ((2, 300), 0.551669873652004, 0.660952380952381, 0.660952380952381, 0.6893738408054743, 0.6469467733601613), ((2, 400), 0.5266320000676548, 0.7190588235294116, 0.7190588235294116, 0.7222923723267565, 0.7178597693977845), ((3, 500), 0.48907450234496985, 0.7346153846153846, 0.7346153846153846, 0.7594859706140806, 0.7257330737148866), ((3, 600), 0.44861228700647965, 0.7636170212765958, 0.7636170212765958, 0.7680353074156651, 0.7625187866481069), ((4, 700), 0.44608796474545503, 0.5918604651162791, 0.5918604651162791, 0.7114090663014866, 0.5205709911446809), ((4, 800), 0.43229351050398324, 0.7464044943820225, 0.7464044943820225, 0.7658888654373842, 0.7401985609777428), ((5, 900), 0.4030474927476657, 0.6920430107526881, 0.6920430107526881, 0.7553949815294411, 0.6683703293010022), ((5, 1000), 0.4092508073938027, 0.7495505617977527, 0.7495505617977527, 0.7721434849045888, 0.7416736328816234), ((6, 1100), 0.42280383130838706, 0.6919767441860465, 0.6919767441860465, 0.7484092674957138, 0.6672307579009153), ((6, 1200), 0.3974765325586001, 0.7859999999999999, 0.7859999999999999, 0.8043306441124465, 0.7825739853204534), ((7, 1300), 0.41337204431549884, 0.7439325842696628, 0.7439325842696628, 0.7820991399149863, 0.7347467583862229), ((7, 1400), 0.373271015096218, 0.7911702127659573, 0.7911702127659574, 0.7979753646827205, 0.7894572020652427), ((8, 1500), 0.3917304729367351, 0.7168131868131868, 0.7168131868131868, 0.7504523908097919, 0.7037471185448203), ((8, 1600), 0.40256163779091325, 0.7632978723404253, 0.7632978723404253, 0.7721423768254838, 0.7608732626053711), ((9, 1700), 0.3707217680329972, 0.7290425531914894, 0.7290425531914894, 0.7918875255567502, 0.7127534124669465), ((9, 1800), 0.37300124747699565, 0.7767415730337078, 0.7767415730337078, 0.8015409638175639, 0.7719944938886195), ((10, 1900), 0.37946617134501426, 0.7306741573033708, 0.7306741573033708, 0.7999571975892364, 0.7128889159838637), ((10, 2000), 0.37088011860192477, 0.6175824175824176, 0.6175824175824176, 0.77668149358524, 0.5491740800599423), ((11, 2100), 0.3570912932195971, 0.7751612903225806, 0.7751612903225806, 0.8088812045990893, 0.7685963356365655), ((11, 2200), 0.3876795197526614, 0.7783333333333333, 0.7783333333333333, 0.8094704165319555, 0.7723802616117694), ((12, 2300), 0.3668056013328688, 0.778452380952381, 0.778452380952381, 0.8098479424572369, 0.7722464513941699), ((12, 2400), 0.3573116387494586, 0.7692045454545454, 0.7692045454545454, 0.8087146670968569, 0.7613304434958033), ((13, 2500), 0.3771612233129041, 0.808390804597701, 0.808390804597701, 0.8122503022154891, 0.8077657865943367), ((13, 2600), 0.3564634816277595, 0.7304761904761905, 0.7304761904761905, 0.8083950503179954, 0.710357033350069), ((14, 2700), 0.3972487446334627, 0.6934444444444445, 0.6934444444444445, 0.7979157907704171, 0.6595028447921325), ((14, 2800), 0.36630184914188824, 0.7101149425287357, 0.7101149425287357, 0.7956882717650298, 0.6855262536166893), ((15, 2900), 0.3751318218267482, 0.7234782608695652, 0.7234782608695652, 0.754619335085453, 0.7106134643093852), ((15, 3000), 0.36051933768759953, 0.6624719101123596, 0.6624719101123595, 0.786437805845507, 0.6182297521352014), ((16, 3100), 0.382606724034185, 0.7361956521739131, 0.7361956521739131, 0.8074382568096066, 0.7182967038244233), ((16, 3200), 0.36188432942615467, 0.8102247191011236, 0.8102247191011236, 0.8178131439764345, 0.8091676940244144), ((17, 3300), 0.38038763243664975, 0.7904301075268815, 0.7904301075268815, 0.8044006217807353, 0.7878614267818669), ((17, 3400), 0.3714197457153746, 0.7677659574468085, 0.7677659574468085, 0.8132684823172363, 0.757559235216882), ((18, 3500), 0.38516169306875647, 0.7497701149425288, 0.7497701149425288, 0.8117087818456529, 0.7349251417697196), ((18, 3600), 0.36074388838476606, 0.8148888888888888, 0.8148888888888888, 0.8227825496037354, 0.8137492478225687), ((19, 3700), 0.3802284069441177, 0.7747252747252745, 0.7747252747252745, 0.7837874051959329, 0.772071099747736), ((19, 3800), 0.3675034424023969, 0.6752380952380952, 0.6752380952380952, 0.7296522883827457, 0.6502629359000208), ((20, 3900), 0.3689995209645966, 0.7929347826086959, 0.7929347826086959, 0.8147366334173199, 0.7892845012734212), ((20, 4000), 0.3802843869704267, 0.7997826086956523, 0.7997826086956523, 0.8096999647113642, 0.7981983781021512), ((21, 4100), 0.3777793676688753, 0.7742528735632184, 0.7742528735632184, 0.8228131788176062, 0.7635752562636696), ((21, 4200), 0.40714316561140795, 0.7935227272727274, 0.7935227272727274, 0.8142498072994158, 0.7898344771496837), ((22, 4300), 0.3862699970256451, 0.7848837209302325, 0.7848837209302325, 0.8193335145366255, 0.7780472742234948), ((22, 4400), 0.3675607168539004, 0.8103409090909092, 0.8103409090909092, 0.8192984104148529, 0.8089739707925823), ((23, 4500), 0.3534346083690832, 0.8197802197802198, 0.8197802197802198, 0.8227118730376434, 0.8192436497061171), ((23, 4600), 0.36465600893852557, 0.8013829787234044, 0.8013829787234044, 0.8250843507462767, 0.7972898476471684), ((24, 4700), 0.3810942191216681, 0.7578888888888888, 0.757888888888889, 0.7767018632047518, 0.7517999941234094), ((24, 4800), 0.3703351379795508, 0.8112500000000001, 0.8112500000000001, 0.8171414744605113, 0.8102947677090296), ((25, 4900), 0.366053937409801, 0.8211494252873561, 0.8211494252873561, 0.8267449823048351, 0.8202864312243778), ((25, 5000), 0.3852137500501197, 0.7902173913043476, 0.7902173913043476, 0.8004064389777994, 0.7878296684042604), ((26, 5100), 0.3969286062887737, 0.7839560439560441, 0.7839560439560441, 0.8132539650734275, 0.7780684530283595), ((26, 5200), 0.38557215302847747, 0.8037078651685392, 0.8037078651685392, 0.826558263414334, 0.7996822071302977), ((27, 5300), 0.37595187234027044, 0.789642857142857, 0.7896428571428571, 0.7974718273588941, 0.7879583371764851), ((27, 5400), 0.3764432963029838, 0.8076543209876543, 0.8076543209876543, 0.8145244982637462, 0.8065567410768079), ((28, 5500), 0.3889087177813053, 0.7934090909090908, 0.793409090909091, 0.799479026572006, 0.7920151341207777), ((28, 5600), 0.3859804611314427, 0.7995454545454546, 0.7995454545454546, 0.8035154817148186, 0.7988520610114147), ((29, 5700), 0.361677511707767, 0.7624175824175825, 0.7624175824175824, 0.8257407035022822, 0.74730286030917), ((29, 5800), 0.36034727957513596, 0.8245555555555555, 0.8245555555555556, 0.8406316339706372, 0.8221976008752739), ((30, 5900), 0.3847862835768815, 0.8136263736263736, 0.8136263736263736, 0.8261776141485846, 0.8115839797461861), ((30, 6000), 0.3846795290381044, 0.778901098901099, 0.778901098901099, 0.7992640265574731, 0.7737950038418189)]\n"
     ]
    }
   ],
   "source": [
    "print(ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=True)\n",
    "eval_loader = PrototypicalData(output_path=config[\"output_path\"],\n",
    "                                    sequence_length=config[\"sequence_length\"],\n",
    "                                    num_classes=config[\"num_classes\"],\n",
    "                                    num_support=config[\"num_support\"],\n",
    "                                    num_queries=config[\"num_queries\"],\n",
    "                                    num_tasks=config[\"num_tasks\"],\n",
    "                                    num_eval_tasks=config[\"num_eval_tasks\"],\n",
    "                                    embedding_size=config[\"embedding_size\"],\n",
    "                                    stop_word_path=config[\"stop_word_path\"],\n",
    "                                    word_vector_path=config[\"word_vector_path\"],\n",
    "                                    is_training=False)\n",
    "train_tasks, train_data_orig = data_loader.gen_data(config[\"train_data\"])\n",
    "eval_tasks, eval_data_orig = eval_loader.gen_data(config[\"eval_data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce7455",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
